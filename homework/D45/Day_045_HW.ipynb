{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging 和 Boosting 的差異："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>訓練樣本</font>方面:\n",
    "### Bagging: \n",
    "- 每一次的訓練集是隨機抽取，抽出可放回。\n",
    "- 每個樣本權重一致，以獨立同分布選取的訓練樣本子集訓練弱分類器。\n",
    "\n",
    "### Boosting: \n",
    "- 每一次的訓練集不變，訓練集之間的選擇不是獨立的。\n",
    "- 每一次選擇的訓練集都是依賴上一次學習得結果，根據錯誤率(給予訓練樣本不同的權重)取樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>分類器</font>方面:\n",
    "### Bagging: \n",
    "- 每個分類器的權重相等。\n",
    "- 透過抽樣 (sampling) 的方式來生成每一棵樹，樹與樹之間是獨立⽣成的\n",
    "- 每個分類器可以並行生成。\n",
    "\n",
    "### Boosting: \n",
    "- 每個分類器都有各自的權重，對於分類誤差大的分類器會有更大的權重。\n",
    "- 透過序列列 (additive) 的⽅式來生成每一顆樹，每棵樹都會與前面的樹關聯。\n",
    "- 每個分類器只能依賴上一次的分類器順序生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>效果</font>方面:\n",
    "### Bagging: \n",
    "- 處理overfitting的model\n",
    "- 降低預測結果的variance\n",
    "\n",
    "### Boosting: \n",
    "- 可能會overfitting\n",
    "- 降低預測結果的bias和variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考資料：\n",
    "\n",
    "- http://violin-tao.blogspot.com/2018/01/ml-ensemble.html\n",
    "- https://blog.csdn.net/abcjennifer/article/details/8164315\n",
    "- https://kknews.cc/zh-tw/education/2aj2xby.html\n",
    "- https://zhuanlan.zhihu.com/p/26112517\n",
    "- https://medium.com/@chih.sheng.huang821/機器學習-ensemble-learning之bagging-boosting和adaboost-af031229ebc3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
